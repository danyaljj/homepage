# jemdoc: menu{MENU}{acc.html}, title{Daniel Khashabi} nofooter


#includeraw{header.html}

~~~
{}{img_left}{profile11.png}{alt text}{170}{}{}
{{<span style="font-weight: bold; font-size: 125%; line-height: 2.0;">Daniel Khashabi </span>}} \n
Assistant Professor,  [https://www.cs.jhu.edu/ Department of Computer Science],
[https://jhu.edu/ Johns Hopkins University] \n
Office: NE366 at [https://maps.app.goo.gl/cx43YcX5fLKsy7MQ8 Marbury building] \n
Email: +danielk{{<img src="https://danielkhashabi.com/files/abababa.png" width="20" height="20" style="margin-bottom: -5px;">}}jhu.edu+ \n
{{<p style="margin-bottom:0.1cm;"></p>}}
Other affiliations:
 - [https://www.clsp.jhu.edu/ Center for Language and Speech Processing]
 - [https://ai.jhu.edu/ Data Science and AI Institute]
 - [https://iaa.jhu.edu/ Institute for Assured Autonomy]
 - [https://www.idies.jhu.edu/ Institute for Data-Intensive Engineering and Science]
 ~~~

{{<h2 id="themes">Research Themes</h2>}}

I am broadly interested in making language-driven AI systems more *helpful*, *reliable*, and *efficient*.
As these systems increasingly engage in reasoning and creative discovery, their impact hinges on balancing open-ended exploration with grounded trustworthiness.
At the core of this agenda lies a tension: creative reasoning thrives on revealing novel connections and deep structural parallels across distant domains, yet it is inherently prone to false associations that can
undermine, rather than enhance, human productivity.
My work draws on algorithmic and statistical tools to develop computational frameworks to harness the benefits of creative reasoning while remaining transparent, verifiable, and
aligned with human values—enabling trustworthy, AI-driven discovery.

I have pursued this vision along three complementary axes:

 - *Understanding the foundations:* What fundamental principles govern the intelligent behavior that emerges from large-scale training? And can we use these insights as guiding principles of scaling?
 - *Reasoning, communication and interaction:* How can we amplify AI’s capacity for reasoning across tasks, contexts, and interactions with the world? How can we characterize the trade-off between generality vs. specialization (sticking to what user wants) in adaptive systems?
 - *Safety, oversight and evaluation:* How can oversight mechanisms (e.g., debate, red teaming, verification) be formalized and automated at scale? How can AI systems balance autonomy with auditing and safety mechanisms to ensure human trust?

#  - /Augmentation/: Designing models that enhance human experience—our aim is to build AI that genuinely benefits people.
# - /Generality/: Building models that generalize across tasks, modalities, and environments, with attention to the long tail of edge cases.
# - /Specificity/: Tailoring models to specific users or domains to improve efficiency and real-world utility.
# - /Reasoning/: Strengthening models' ability to communicate via /reasons/, both for creative problem-solving and for communicating decisions through clear explanations.
# - /Interpretability/: Understanding and monitoring how models behave; e.g., how in-context learning emerges, when it works, and when it fails.
# - /Safety & Transparency/: Advancing reliability and transparency in AI—essential for responsible deployment in high-stakes settings.
# - /Applications/:  Exploring high-impact uses of AI, especially in advancing *scientific discovery.*


Our research is driven by a key real application: accelerating *scientific discovery* in an era where /knowledge grows faster than any individual can absorb/.

Most of my research is aligned with the following research communities: /natural language processing/ (ACL, NAACL, EMNLP), /machine learning/ and /AI/  (COLM, ICLR, NeurIPS, ICML, AAAI, IJCAI).

~~~

#includeraw{prospective2.html}

~~~

- [https://ai.jhu.edu/careers/postdoctoral-fellowship-program/ *Postdoc positions*] -- applications due January 23, 2026.

{{<h2 id="talks">Recent Talks</h2>}}

- 2025, JHU  MLxAstro/Cosmo Meeting ([https://danielkhashabi.com/files/2025_astro_talk/2025-astro_talk.pdf slides])
- 2025, Apple Workshop on Reasoning and Planning ([https://danielkhashabi.com/files/2025_apple_workshop/2025-apple-workshop.pdf slides])
- 2025, University of Pennsylvania Computational Linguistics lunch ([https://danielkhashabi.com/files/2025_clunch_talk/2025-penn-clunch.pdf slides])
- 2024, University of Cambridge the Language Technology Lab seminar ([https://danielkhashabi.com/files/2024_cambridge_talk/2024-cambridge2.pdf slides])
- 2024, Oracle Labs ML seminar ([http://danielkhashabi.com/files/2024_oracle/2024-oracle.pdf slides])
- 2024, Tel Aviv NLP seminar ([http://danielkhashabi.com/files/2024_oracle/2024-TAU.pdf slides])
- 2024, Forum on ``Engineered AI Systems'' ([http://danielkhashabi.com/files/2024_NAE/2024-Khashabi_NAE.pdf slides])
- 2024, Keynote at ``Engineering for Professionals'' quarterly meeting ([http://danielkhashabi.com/files/2024_ep_conference/2024-EP-self-improve.pdf slides])
- 2024, Workshop on ``LLMs for Healthy Aging'' ([http://danielkhashabi.com/files/2023_aitc/2023-jhu-aitc.pdf slides])
- 2023, NYU ``Text-as-Data'' talk series ([http://danielkhashabi.com/files/2023_nyu/2023-nyu2-slides.pdf slides])
- 2023, Hopkins Center for Language and Speech Technologies seminar ([https://www.youtube.com/watch?v=YuxmtgBk-Ls video])
- 2023, Hopkins Electrical Engineering department seminars ([http://danielkhashabi.com/files/2023_ece_talk/2023-ece-jhu.pdf slides])
- 2023, Amazon ``Human in the Loop'' seminar
- 2023, Hopkins Center for Health Security seminars ([http://danielkhashabi.com/files/2023_public_health/2023-jhu-public-health-split.pdf slides])
- 2023, UMD Computational Linguistics seminar ([http://danielkhashabi.com/files/2023_umd_talk/umd-talk-2023-split.pdf slides])
- 2023, Applied Physics Lab, Intelligent Systems Center seminars
- 2022, University of Tehran NLP seminar
- 2021, University of Glasgow IR seminar ([http://danielkhashabi.com/files/2021_glasgow/glasgow-talk-appril-2021.pptx slides])
- 2021, Johns Hopkins University ([http://danielkhashabi.com/files/2022_jhu_talk/jhu_talk-feb-2022-split.pdf slides])
- 2021, Google AI ([http://danielkhashabi.com/files/2021_google_talk/google-talk-march-2021.pdf slides])
- 2021, UCLA Big Data and ML seminar ([http://danielkhashabi.com/files/2021_ucla_talk/ucla-talk-march-2021.pptx slides])
- 2021, USC NLP seminar ([http://danielkhashabi.com/files/2021_usc/usc:isi-talk-march-2021.pptx slides])
- 2020, Tel Aviv University NLP seminar ([http://danielkhashabi.com/files/2020_unifiedqa/unifiedqa_tau_talk_split.pdf slides])
- 2019, [https://freuder.wordpress.com/pthg-19-the-third-workshop-on-progress-towards-the-holy-grail/The Workshop on Progress Towards the Holy Grail], Conference on Constraint Programming (CP), 2019. ([http://danielkhashabi.com/files/2019_talk_holy_grail_workshop/daniel-kh-holy-grail-workshop-2019.pdf slides])
- 2019, CMU LTI seminar ([http://danielkhashabi.com/files/2019_talk_indirect_supervision/danielkh_job_talk_small_supervision_split.pdf slides])
- 2018, NYU NLP seminar [https://docs.google.com/presentation/d/1KZxE0_LANeRYaShGP2cjvbRTaR2V7F8N36xQ8004r2o/edit?usp=sharing  Reasoning-Driven Question Answering].
- 2018, Stanford NLP seminar  ([https://docs.google.com/presentation/d/11QnDUYXB9q06HIyZxmHcb1BrwcdStjjHPNOC3AnlTsc/edit?usp=sharing slides])
- 2018, Mid-Atlantic Student Colloquium on Speech, Language and Learning ([https://docs.google.com/presentation/d/1KmGQfbeUitZOum4s6cPTqwuJJfTdxlQMeV_Go2_8Jz0/edit?usp=sharing slides])


{{<h2 id="teaching">Teaching</h2>}}
 - CS 601.471/671, NLP: Self-supervised Models: [https://self-supervised.cs.jhu.edu/sp2023/ Spring 2023], [https://self-supervised.cs.jhu.edu/sp2024/ Spring 2024], [https://self-supervised.cs.jhu.edu/sp2025/ Spring 2025] (not teaching in Spring 2026; apologies to all students who wanted to take this course)
 - CS 601.771, Advances in Self-supervised Models: [https://self-supervised.cs.jhu.edu/fa2022/ Fall 2022], [https://self-supervised.cs.jhu.edu/fa2024/ Fall 2024], [https://self-supervised.cs.jhu.edu/fa2025/ Fall 2025]


#== Notes
# -  [learn.html "Learning Algorithms--or blend of computation and statistics", an outdated collection of notes]


{{<h2 id="lab">Intelligence Amplification Lab (IALab)</h2>}}

  PhD students:
   - [https://scholar.google.com/citations?user=t3Hhnx8AAAAJ&hl=en/ Adam Byerly]
   - [https://jackz.io/ Jack Jingyu Zhang] - co-advised w/ Benjamin Van Durme
   - [https://andrewwnlp.github.io/ Andrew Wang] - co-advised w/ Nick Andrews
   - [https://jefferyo.github.io/ Jiefu Ou] - co-advised w/ Benjamin Van Durme
   - [https://tianjianl.github.io/ Tianjian Li]
   - [https://isgla.github.io/ Hannah Gonzalez] - co-advised w/ Benjamin Van Durme
   - [https://cozheyuanzhangde.github.io/ Zheyuan "Brian" Zhang] - co-advised w/ Tianmin Shu
   - [https://austenliao1.github.io/ Austen Liao] - co-advised w/ Benjamin Van Durme

 Here’s a [https://x.com/DanielKhashabi/status/1985487186326938088 team photo] from our recent fun outing.\n
 We’re also grateful to collaborate with a number of exceptional PhD, MS and undergraduate students who are not listed here.



{{<h2 id="publication">Publication</h2>}}

*Disclaimer:* This material is presented to ensure the timely dissemination of scholarly works. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms invoked by each author's copyright. \n
==== 

#include{publication.jemdoc}

