# jemdoc: menu{MENU}{acc.html}, title{Daniel Khashabi} nofooter

~~~
{}{img_left}{profile11.png}{alt text}{170}{}{}
{{<span style="font-weight: bold; font-size: 125%; line-height: 2.0;">Daniel Khashabi </span>}} \n
Assistant Professor,  [https://www.cs.jhu.edu/ Department of Computer Science],
[https://jhu.edu/ Johns Hopkins University] \n
Office: Hackerman Hall 316B \n
Email: +danielk{{<img src="https://danielkhashabi.com/files/abababa.png" width="20" height="20" style="margin-bottom: -5px;">}}jhu.edu+ \n
{{<p style="margin-bottom:0.1cm;"></p>}}
Other affiliations:
 - [https://www.clsp.jhu.edu/ Center for Language and Speech Processing]
 - [https://ai.jhu.edu/ Data Science and AI Institute]
 - [https://iaa.jhu.edu/ Institute for Assured Autonomy]
 - [https://www.idies.jhu.edu/ Institute for Data-Intensive Engineering and Science]
 ~~~

{{<h2 id="themes">Research Themes</h2>}}

Broadly, my research is anchored around the use of *natural language as a key medium for communication* between humans and AI systems and is driven by the goal of making these systems *more helpful*, *reliable*, and *efficient*.


In pursuit of these objectives, my team and I have made various endeavors toward the following more specific themes:
 - /Augmentation/: Designing models that enhance human experience—our aim is to build AI that genuinely benefits people.
 - /Generality/: Building models that generalize across tasks, modalities, and environments, with attention to the long tail of edge cases.
 - /Specificity/: Tailoring models to specific users or domains to improve efficiency and real-world utility.
 - /Reasoning/: Strengthening models' ability to communicate via /reasons/, both for creative problem-solving and for communicating decisions through clear explanations.
 - /Interpretability/: Understanding and monitoring how models behave; e.g., how in-context learning emerges, when it works, and when it fails.
 - /Safety & Transparency/: Advancing reliability and transparency in AI—essential for responsible deployment in high-stakes settings.
 - /Applications/:  Exploring high-impact uses of AI, especially in advancing *scientific discovery.*

Most of my research is aligned with the following research communities: /natural language processing/ (ACL, NAACL, EMNLP), /machine learning/  (ICLR, NeurIPS, ICML), and /artificial intelligence/ (AAAI, IJCAI).

~~~

#includeraw{prospective.html}

~~~

{{<h2 id="talks">Recent Talks</h2>}}

- 2025, University of Pennsylvania Computational Linguistics lunch ([https://danielkhashabi.com//files/2025_clunch_talk/2025-penn-clunch.pdf slides])
- 2024, University of Cambridge the Language Technology Lab seminar ([https://danielkhashabi.com//files/2024_cambridge_talk/2024-cambridge2.pdf slides])
- 2024, Oracle Labs ML seminar ([http://danielkhashabi.com/files/2024_oracle/2024-oracle.pdf slides])
- 2024, Tel Aviv NLP seminar ([http://danielkhashabi.com/files/2024_oracle/2024-TAU.pdf slides])
- 2024, Forum on ``Engineered AI Systems'' ([http://danielkhashabi.com/files/2024_NAE/2024-Khashabi_NAE.pdf slides])
- 2024, Keynote at ``Engineering for Professionals'' quarterly meeting ([http://danielkhashabi.com/files/2024_ep_conference/2024-EP-self-improve.pdf slides])
- 2024, Workshop on ``LLMs for Healthy Aging'' ([http://danielkhashabi.com/files/2023_aitc/2023-jhu-aitc.pdf slides])
- 2023, NYU ``Text-as-Data'' talk series ([http://danielkhashabi.com/files/2023_nyu/2023-nyu2-slides.pdf slides])
- 2023, Hopkins Center for Language and Speech Technologies seminar ([https://www.youtube.com/watch?v=YuxmtgBk-Ls video])
- 2023, Hopkins Electrical Engineering department seminars ([http://danielkhashabi.com/files/2023_ece_talk/2023-ece-jhu.pdf slides])
- 2023, Amazon ``Human in the Loop'' seminar
- 2023, Hopkins Center for Health Security seminars ([http://danielkhashabi.com/files/2023_public_health/2023-jhu-public-health-split.pdf slides])
- 2023, UMD Computational Linguistics seminar ([http://danielkhashabi.com/files/2023_umd_talk/umd-talk-2023-split.pdf slides])
- 2023, Applied Physics Lab, Intelligent Systems Center seminars
- 2022, University of Tehran NLP seminar
- 2021, University of Glasgow IR seminar ([http://danielkhashabi.com/files/2021_glasgow/glasgow-talk-appril-2021.pptx slides])
- 2021, Johns Hopkins University ([http://danielkhashabi.com/files/2022_jhu_talk/jhu_talk-feb-2022-split.pdf slides])
- 2021, Google AI ([http://danielkhashabi.com/files/2021_google_talk/google-talk-march-2021.pdf slides])
- 2021, UCLA Big Data and ML seminar ([http://danielkhashabi.com/files/2021_ucla_talk/ucla-talk-march-2021.pptx slides])
- 2021, USC NLP seminar ([http://danielkhashabi.com/files/2021_usc/usc:isi-talk-march-2021.pptx slides])
- 2020, Tel Aviv University NLP seminar ([http://danielkhashabi.com/files/2020_unifiedqa/unifiedqa_tau_talk_split.pdf slides])
- 2019, [https://freuder.wordpress.com/pthg-19-the-third-workshop-on-progress-towards-the-holy-grail/The Workshop on Progress Towards the Holy Grail], Conference on Constraint Programming (CP), 2019. ([http://danielkhashabi.com/files/2019_talk_holy_grail_workshop/daniel-kh-holy-grail-workshop-2019.pdf slides])
- 2019, CMU LTI seminar ([http://danielkhashabi.com/files/2019_talk_indirect_supervision/danielkh_job_talk_small_supervision_split.pdf slides])
- 2018, NYU NLP seminar [https://docs.google.com/presentation/d/1KZxE0_LANeRYaShGP2cjvbRTaR2V7F8N36xQ8004r2o/edit?usp=sharing  Reasoning-Driven Question Answering].
- 2018, Stanford NLP seminar  ([https://docs.google.com/presentation/d/11QnDUYXB9q06HIyZxmHcb1BrwcdStjjHPNOC3AnlTsc/edit?usp=sharing slides])
- 2018, Mid-Atlantic Student Colloquium on Speech, Language and Learning ([https://docs.google.com/presentation/d/1KmGQfbeUitZOum4s6cPTqwuJJfTdxlQMeV_Go2_8Jz0/edit?usp=sharing slides])


{{<h2 id="teaching">Teaching</h2>}}
 - CS 601.471/671, NLP: Self-supervised Models: [https://self-supervised.cs.jhu.edu/sp2023/ Spring 2023], [https://self-supervised.cs.jhu.edu/sp2024/ Spring 2024], [https://self-supervised.cs.jhu.edu/sp2025/ Spring 2025]
 - CS 601.771, Advances in Self-supervised Models: [https://self-supervised.cs.jhu.edu/fa2022/ Fall 2022], [https://self-supervised.cs.jhu.edu/fa2024/ Fall 2024]





#== Notes
# -  [learn.html "Learning Algorithms--or blend of computation and statistics", an outdated collection of notes]


  {{<h2 id="lab">Intelligence Amplification Lab (IALab)</h2>}}
  PhD students:
   - [https://scholar.google.com/citations?user=t3Hhnx8AAAAJ&hl=en/ Adam Byerly]
   - [https://jackz.io/ Jack Jingyu Zhang] - co-advised w/ Benjamin Van Durme
   - [https://andrewwnlp.github.io/ Andrew Wang] - co-advised w/ Nick Andrews
   - [https://jefferyo.github.io/ Jiefu Ou] - co-advised w/ Benjamin Van Durme
   - [https://tianjianl.github.io/ Tianjian Li]
   - [https://isgla.github.io/ Hannah Gonzalez] - co-advised w/ Benjamin Van Durme
   - [https://cozheyuanzhangde.github.io/ Zheyuan "Brian" Zhang] - co-advised w/ Tianmin Shu

 We’re also grateful to collaborate with a number of exceptional PhD, MS and undergraduate students who are not listed here.



{{<h2 id="publication">Publication</h2>}}

*Disclaimer:* This material is presented to ensure the timely dissemination of scholarly works. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms invoked by each author's copyright. \n
==== 

#include{publication.jemdoc}

